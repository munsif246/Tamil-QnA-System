{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:08:59.807694Z",
     "iopub.status.busy": "2023-01-06T10:08:59.807151Z",
     "iopub.status.idle": "2023-01-06T10:08:59.814406Z",
     "shell.execute_reply": "2023-01-06T10:08:59.813150Z",
     "shell.execute_reply.started": "2023-01-06T10:08:59.807657Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import default_data_collator\n",
    "import collections\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:09:01.118061Z",
     "iopub.status.busy": "2023-01-06T10:09:01.117716Z",
     "iopub.status.idle": "2023-01-06T10:09:15.042997Z",
     "shell.execute_reply": "2023-01-06T10:09:15.041784Z",
     "shell.execute_reply.started": "2023-01-06T10:09:01.118028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda112, which is not installed.\n",
      "cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda110, which is not installed.\n",
      "s3fs 2021.6.1 requires fsspec==2021.06.1, but you have fsspec 2021.6.0 which is incompatible.\n",
      "pytorch-lightning 1.3.8 requires fsspec[http]!=2021.06.0,>=2021.05.0, but you have fsspec 2021.6.0 which is incompatible.\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires dask<=2021.5.1,>=2021.4.0, but you have dask 2021.6.2 which is incompatible.\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires distributed<=2021.5.1,>=2.22.0, but you have distributed 2021.6.2 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall fsspec -qq -y\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:09:15.045530Z",
     "iopub.status.busy": "2023-01-06T10:09:15.045120Z",
     "iopub.status.idle": "2023-01-06T10:09:15.057861Z",
     "shell.execute_reply": "2023-01-06T10:09:15.056866Z",
     "shell.execute_reply.started": "2023-01-06T10:09:15.045486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_DISABLED=True\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_DISABLED=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:09:15.065268Z",
     "iopub.status.busy": "2023-01-06T10:09:15.062147Z",
     "iopub.status.idle": "2023-01-06T10:09:15.086000Z",
     "shell.execute_reply": "2023-01-06T10:09:15.084882Z",
     "shell.execute_reply.started": "2023-01-06T10:09:15.065238Z"
    }
   },
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "    \n",
    "    def import_dataset(self):\n",
    "        df = pd.read_csv(self.path)\n",
    "        return df\n",
    "    \n",
    "    def clean_df(self):\n",
    "        df = self.import_dataset()\n",
    "        df['isnull'] = df.context.isnull()\n",
    "        df = df[df['isnull'] !=True]\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.df = df\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def no_of_uniq_ids(self):\n",
    "        df = self.clean_df()\n",
    "        return df.id.nunique()\n",
    "    \n",
    "    def import_tokenizer(self, checkpoint):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        self.tokenizer = tokenizer\n",
    "        return tokenizer\n",
    "    \n",
    "    def token_count_distribution(self, tokenizer):\n",
    "        df = self.clean_df()\n",
    "        df['num_tokens_context'] = df['context'].apply(lambda t: len(tokenizer(t)['input_ids']))\n",
    "        return train['num_tokens_context'].hist()\n",
    "    \n",
    "    def convert_answers(self,r):\n",
    "        start = r[0]\n",
    "        text = r[1]\n",
    "        return {\n",
    "            'answer_start': [start],\n",
    "            'text': [text]\n",
    "        }\n",
    "    \n",
    "    def shuffle(self):\n",
    "        df = self.clean_df()\n",
    "        df = df.sample(frac=1, random_state=42)\n",
    "        df['answers'] = df[['answer_start', 'answer_text']].apply(self.convert_answers, axis=1)\n",
    "        return df\n",
    "        \n",
    "    def split_data(self):\n",
    "        df = self.shuffle()\n",
    "        df_train = df[:-64].reset_index(drop=True)\n",
    "        df_valid = df[-64:].reset_index(drop=True)\n",
    "        train_dataset = Dataset.from_pandas(df_train)\n",
    "        valid_dataset = Dataset.from_pandas(df_valid)\n",
    "        \n",
    "        return train_dataset,valid_dataset\n",
    "    \n",
    "    \n",
    "    def prepare_train_features(self,examples):\n",
    "        max_length = 384 \n",
    "        doc_stride = 128\n",
    "        pad_on_right = tokenizer.padding_side == \"right\"\n",
    "    \n",
    "        examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "        tokenized_examples = tokenizer(\n",
    "            examples[\"question\" if pad_on_right else \"context\"],\n",
    "            examples[\"context\" if pad_on_right else \"question\"],\n",
    "            truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "        offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "        tokenized_examples[\"start_positions\"] = []\n",
    "        tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "        for i, offsets in enumerate(offset_mapping):\n",
    "            input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "            cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "            sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "            sample_index = sample_mapping[i]\n",
    "            answers = examples[\"answers\"][sample_index]\n",
    "            if len(answers[\"answer_start\"]) == 0:\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                start_char = answers[\"answer_start\"][0]\n",
    "                end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "                token_start_index = 0\n",
    "                while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                    token_start_index += 1\n",
    "\n",
    "                token_end_index = len(input_ids) - 1\n",
    "                while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                    token_end_index -= 1\n",
    "\n",
    "                if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                    tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                    tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "                else:\n",
    "                    \n",
    "                    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                        token_start_index += 1\n",
    "                    tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                    while offsets[token_end_index][1] >= end_char:\n",
    "                        token_end_index -= 1\n",
    "                    tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "        return tokenized_examples\n",
    "        \n",
    "    def tokenized_df(self):\n",
    "        train_dataset,valid_dataset = self.split_data()\n",
    "        tokenized_train_ds = train_dataset.map(self.prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\n",
    "        tokenized_valid_ds = valid_dataset.map(self.prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\n",
    "        return tokenized_train_ds,tokenized_valid_ds\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:09:15.089834Z",
     "iopub.status.busy": "2023-01-06T10:09:15.089249Z",
     "iopub.status.idle": "2023-01-06T10:09:41.686367Z",
     "shell.execute_reply": "2023-01-06T10:09:41.685496Z",
     "shell.execute_reply.started": "2023-01-06T10:09:15.089789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84edc02a87f54da5a9167b14eb086597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341b2637ad034446a0b37b97c19f6106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess2 = preprocess('/kaggle/input/df-tam-csv/df_tam3.csv')\n",
    "tokenizer = preprocess2.import_tokenizer('/kaggle/input/xlm-roberta-squad2/deepset/xlm-roberta-base-squad2')\n",
    "#preprocess2.token_count_distribution(tokenizer)\n",
    "train_dataset,valid_dataset = preprocess2.split_data()\n",
    "tokenized_train_ds,tokenized_valid_ds = preprocess2.tokenized_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:10:57.199648Z",
     "iopub.status.busy": "2023-01-06T10:10:57.199283Z",
     "iopub.status.idle": "2023-01-06T10:10:57.209290Z",
     "shell.execute_reply": "2023-01-06T10:10:57.208243Z",
     "shell.execute_reply.started": "2023-01-06T10:10:57.199616Z"
    }
   },
   "outputs": [],
   "source": [
    "class model_building:\n",
    "    \n",
    "    def __init__(self,model_checkpoint):\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "    \n",
    "    def import_model(self):\n",
    "        model = AutoModelForQuestionAnswering.from_pretrained(self.model_checkpoint)\n",
    "        return model\n",
    "    \n",
    "    def training_parameters(self,learning_rate=2e-5,batch_size = 4,weight_decay=0.01,num_train_epochs=1):\n",
    "        args = TrainingArguments(\n",
    "            f\"tamil-qa\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate=learning_rate,\n",
    "            warmup_ratio=0.1,\n",
    "            gradient_accumulation_steps=8,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "        return args\n",
    "    \n",
    "    def train_model(self, model, args, tokenized_train_ds,tokenized_valid_ds):\n",
    "        data_collator = default_data_collator\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            train_dataset=tokenized_train_ds,\n",
    "            eval_dataset=tokenized_valid_ds,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "        trainer.train()\n",
    "        \n",
    "        return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:10:57.749921Z",
     "iopub.status.busy": "2023-01-06T10:10:57.749591Z",
     "iopub.status.idle": "2023-01-06T10:33:22.464322Z",
     "shell.execute_reply": "2023-01-06T10:33:22.463202Z",
     "shell.execute_reply.started": "2023-01-06T10:10:57.749891Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='764' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [764/764 22:13, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.242223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.917000</td>\n",
       "      <td>1.191093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelbuild = model_building('/kaggle/input/xlm-roberta-squad2/deepset/xlm-roberta-base-squad2')\n",
    "model = modelbuild.import_model()\n",
    "args = modelbuild.training_parameters(num_train_epochs=2)\n",
    "trainer = modelbuild.train_model(model, args, tokenized_train_ds,tokenized_valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:33:22.472084Z",
     "iopub.status.busy": "2023-01-06T10:33:22.471518Z",
     "iopub.status.idle": "2023-01-06T10:33:22.495828Z",
     "shell.execute_reply": "2023-01-06T10:33:22.494839Z",
     "shell.execute_reply.started": "2023-01-06T10:33:22.472052Z"
    }
   },
   "outputs": [],
   "source": [
    "class answer_extraction:\n",
    "    \n",
    "    def __init__(self, valid_dataset):\n",
    "        self.valid_dataset = valid_dataset\n",
    "    \n",
    "    def prepare_validation_features(self,examples):\n",
    "        max_length = 384 \n",
    "        doc_stride = 128\n",
    "        pad_on_right = tokenizer.padding_side == \"right\"\n",
    "        \n",
    "        examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "        tokenized_examples = tokenizer(\n",
    "            examples[\"question\" if pad_on_right else \"context\"],\n",
    "            examples[\"context\" if pad_on_right else \"question\"],\n",
    "            truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "        tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "        for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "            sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "            context_index = 1 if pad_on_right else 0\n",
    "\n",
    "            sample_index = sample_mapping[i]\n",
    "            tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "            tokenized_examples[\"offset_mapping\"][i] = [\n",
    "                (o if sequence_ids[k] == context_index else None)\n",
    "                for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "            ]\n",
    "\n",
    "        return tokenized_examples\n",
    "    \n",
    "    def apply_validation_feature(self):\n",
    "        valid_dataset = self.valid_dataset\n",
    "        validation_features = valid_dataset.map(\n",
    "            self.prepare_validation_features,\n",
    "            batched=True,\n",
    "            remove_columns=valid_dataset.column_names\n",
    "        )\n",
    "        return validation_features\n",
    "        \n",
    "    def valid(self):\n",
    "        validation_features = self.apply_validation_feature()\n",
    "        valid_feats_small = validation_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\n",
    "        return valid_feats_small\n",
    "    \n",
    "    def raw_predict(self,trainer):\n",
    "        valid_feats_small = self.valid()\n",
    "        raw_predictions = trainer.predict(valid_feats_small)\n",
    "        return raw_predictions\n",
    "    \n",
    "    def postprocess_qa_predictions(self, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "        examples = self.valid_dataset\n",
    "        features = self.apply_validation_feature()\n",
    "        \n",
    "        all_start_logits, all_end_logits = raw_predictions\n",
    "        example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "        features_per_example = collections.defaultdict(list)\n",
    "        \n",
    "        for i, feature in enumerate(features):\n",
    "            features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "        predictions = collections.OrderedDict()\n",
    "\n",
    "        print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "        for example_index, example in enumerate(tqdm(examples)):\n",
    "            feature_indices = features_per_example[example_index]\n",
    "\n",
    "            min_null_score = None \n",
    "            valid_answers = []\n",
    "\n",
    "            context = example[\"context\"]\n",
    "            for feature_index in feature_indices: \n",
    "                start_logits = all_start_logits[feature_index]\n",
    "                end_logits = all_end_logits[feature_index]\n",
    "              \n",
    "                offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "                cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "                feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "                if min_null_score is None or min_null_score < feature_null_score:\n",
    "                    min_null_score = feature_null_score\n",
    "\n",
    "                start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                for start_index in start_indexes:\n",
    "                    for end_index in end_indexes:\n",
    "                        if (\n",
    "                            start_index >= len(offset_mapping)\n",
    "                            or end_index >= len(offset_mapping)\n",
    "                            or offset_mapping[start_index] is None\n",
    "                            or offset_mapping[end_index] is None\n",
    "                        ):\n",
    "                            continue\n",
    "                        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                            continue\n",
    "\n",
    "                        start_char = offset_mapping[start_index][0]\n",
    "                        end_char = offset_mapping[end_index][1]\n",
    "                        valid_answers.append(\n",
    "                            {\n",
    "                                \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                                \"text\": context[start_char: end_char]\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            if len(valid_answers) > 0:\n",
    "                best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "            else:\n",
    "               \n",
    "                best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:33:22.498224Z",
     "iopub.status.busy": "2023-01-06T10:33:22.497743Z",
     "iopub.status.idle": "2023-01-06T10:33:22.841926Z",
     "shell.execute_reply": "2023-01-06T10:33:22.840890Z",
     "shell.execute_reply.started": "2023-01-06T10:33:22.498035Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_exact_match(row):\n",
    "    return int(row[0] == row[1])\n",
    "\n",
    "def jaccard(row): \n",
    "    str1 = row[0]\n",
    "    str2 = row[1]\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def compute_f1(row):\n",
    "    truth = row[0]\n",
    "    prediction = row[1]\n",
    "    pred_tokens = prediction.split()\n",
    "    truth_tokens = truth.split()\n",
    "    \n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:33:22.892434Z",
     "iopub.status.busy": "2023-01-06T10:33:22.891748Z",
     "iopub.status.idle": "2023-01-06T10:33:29.725118Z",
     "shell.execute_reply": "2023-01-06T10:33:29.724022Z",
     "shell.execute_reply.started": "2023-01-06T10:33:22.892389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c133e898964307a2fbbd67fad3fbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3f761d4ffe41bb8616212f865edff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3866734db24363bf4e4768d5cbda09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7f51184be14a18a7204a8a74dbb6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e7bf717e4e40a88158b4676cec9d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing2 = answer_extraction(valid_dataset)\n",
    "validation_features = testing2.apply_validation_feature()\n",
    "valid_feats_small = testing2.valid()\n",
    "raw_predictions = testing2.raw_predict(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:33:29.729685Z",
     "iopub.status.busy": "2023-01-06T10:33:29.729202Z",
     "iopub.status.idle": "2023-01-06T10:33:31.360159Z",
     "shell.execute_reply": "2023-01-06T10:33:31.359192Z",
     "shell.execute_reply.started": "2023-01-06T10:33:29.729653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557b131375954f1aab00418e5f4647a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 64 example predictions split into 169 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e793a6cfff4f69b7c9d989e1ae402a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = testing2.postprocess_qa_predictions( \n",
    "                                    raw_predictions.predictions, n_best_size = 20, \n",
    "                                    max_answer_length = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:33:31.361897Z",
     "iopub.status.busy": "2023-01-06T10:33:31.361555Z",
     "iopub.status.idle": "2023-01-06T10:33:31.382947Z",
     "shell.execute_reply": "2023-01-06T10:33:31.381993Z",
     "shell.execute_reply.started": "2023-01-06T10:33:31.361859Z"
    }
   },
   "outputs": [],
   "source": [
    "references = [{\"id\": ex[\"id\"], \"answer_text\": ex[\"answers\"]['text'][0]} for ex in valid_dataset]\n",
    "res = pd.DataFrame(references)\n",
    "res['prediction'] = res['id'].apply(lambda r: predictions[r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:33:31.385452Z",
     "iopub.status.busy": "2023-01-06T10:33:31.385089Z",
     "iopub.status.idle": "2023-01-06T10:33:31.422111Z",
     "shell.execute_reply": "2023-01-06T10:33:31.421268Z",
     "shell.execute_reply.started": "2023-01-06T10:33:31.385416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ade0a31c</td>\n",
       "      <td>விளையாட்டு அல்லது இரை</td>\n",
       "      <td>பாலூட்டிகள் மற்றும் பறவைகள்</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd10ea93</td>\n",
       "      <td>சுத்திகரிப்பு</td>\n",
       "      <td>பெஞ்ச்மார்க்</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89eaa0f8</td>\n",
       "      <td>அமிதாபா</td>\n",
       "      <td>அமிதாபா புத்தர்</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35173f15</td>\n",
       "      <td>பாதி</td>\n",
       "      <td>பாதிப் பகுதிகள்</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6e8a6d7</td>\n",
       "      <td>பில்லி</td>\n",
       "      <td>பில்லி டிப்டன்</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            answer_text                    prediction  jaccard  EM  \\\n",
       "0  ade0a31c  விளையாட்டு அல்லது இரை   பாலூட்டிகள் மற்றும் பறவைகள்      0.0   0   \n",
       "1  dd10ea93          சுத்திகரிப்பு                  பெஞ்ச்மார்க்      0.0   0   \n",
       "2  89eaa0f8                அமிதாபா               அமிதாபா புத்தர்      0.5   0   \n",
       "3  35173f15                   பாதி               பாதிப் பகுதிகள்      0.0   0   \n",
       "4  b6e8a6d7                 பில்லி                பில்லி டிப்டன்      0.5   0   \n",
       "\n",
       "         F1  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.666667  \n",
       "3  0.000000  \n",
       "4  0.666667  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['jaccard'] = res[['answer_text', 'prediction']].apply(jaccard, axis=1)\n",
    "res ['EM'] = res[['answer_text', 'prediction']].apply(compute_exact_match, axis=1)\n",
    "res ['F1'] = res[['answer_text', 'prediction']].apply(compute_f1, axis=1)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T10:33:31.423877Z",
     "iopub.status.busy": "2023-01-06T10:33:31.423515Z",
     "iopub.status.idle": "2023-01-06T10:33:31.455193Z",
     "shell.execute_reply": "2023-01-06T10:33:31.448714Z",
     "shell.execute_reply.started": "2023-01-06T10:33:31.423840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.5918395406676655\n",
      "Jaccard score:  0.5547619047619048\n",
      "Exact match score:  0.125\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score: ',res.F1.mean())\n",
    "print('Jaccard score: ',res.jaccard.mean())\n",
    "print('Exact match score: ', res.EM.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
