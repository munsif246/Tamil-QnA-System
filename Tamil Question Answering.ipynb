{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T08:35:14.926840Z",
     "iopub.status.busy": "2023-01-07T08:35:14.926165Z",
     "iopub.status.idle": "2023-01-07T08:35:22.220704Z",
     "shell.execute_reply": "2023-01-07T08:35:22.219772Z",
     "shell.execute_reply.started": "2023-01-07T08:35:14.926735Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import default_data_collator\n",
    "import collections\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T08:35:22.223940Z",
     "iopub.status.busy": "2023-01-07T08:35:22.223314Z",
     "iopub.status.idle": "2023-01-07T08:35:32.261907Z",
     "shell.execute_reply": "2023-01-07T08:35:32.260906Z",
     "shell.execute_reply.started": "2023-01-07T08:35:22.223899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-cloud 0.1.13 requires tensorflow<3.0,>=1.15.0, which is not installed.\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda112, which is not installed.\n",
      "cudf 21.6.1+2.g101fc0fda4 requires cupy-cuda110, which is not installed.\n",
      "s3fs 2021.6.1 requires fsspec==2021.06.1, but you have fsspec 2021.6.0 which is incompatible.\n",
      "pytorch-lightning 1.3.8 requires fsspec[http]!=2021.06.0,>=2021.05.0, but you have fsspec 2021.6.0 which is incompatible.\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires dask<=2021.5.1,>=2021.4.0, but you have dask 2021.6.2 which is incompatible.\n",
      "dask-cudf 21.6.1+2.g101fc0fda4 requires distributed<=2021.5.1,>=2.22.0, but you have distributed 2021.6.2 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall fsspec -qq -y\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T08:35:32.269468Z",
     "iopub.status.busy": "2023-01-07T08:35:32.267179Z",
     "iopub.status.idle": "2023-01-07T08:35:32.280650Z",
     "shell.execute_reply": "2023-01-07T08:35:32.279531Z",
     "shell.execute_reply.started": "2023-01-07T08:35:32.269418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_DISABLED=True\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_DISABLED=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T08:35:32.288407Z",
     "iopub.status.busy": "2023-01-07T08:35:32.285949Z",
     "iopub.status.idle": "2023-01-07T08:35:32.319869Z",
     "shell.execute_reply": "2023-01-07T08:35:32.319118Z",
     "shell.execute_reply.started": "2023-01-07T08:35:32.288366Z"
    }
   },
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "    \n",
    "    def import_dataset(self):\n",
    "        df = pd.read_csv(self.path)\n",
    "        return df\n",
    "    \n",
    "    def clean_df(self):\n",
    "        df = self.import_dataset()\n",
    "        df['isnull'] = df.context.isnull()\n",
    "        df = df[df['isnull'] !=True]\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.df = df\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def no_of_uniq_ids(self):\n",
    "        df = self.clean_df()\n",
    "        return df.id.nunique()\n",
    "    \n",
    "    def import_tokenizer(self, checkpoint):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        self.tokenizer = tokenizer\n",
    "        return tokenizer\n",
    "    \n",
    "    def token_count_distribution(self, tokenizer):\n",
    "        df = self.clean_df()\n",
    "        df['num_tokens_context'] = df['context'].apply(lambda t: len(tokenizer(t)['input_ids']))\n",
    "        return train['num_tokens_context'].hist()\n",
    "    \n",
    "    def convert_answers(self,r):\n",
    "        start = r[0]\n",
    "        text = r[1]\n",
    "        return {\n",
    "            'answer_start': [start],\n",
    "            'text': [text]\n",
    "        }\n",
    "    \n",
    "    def shuffle(self):\n",
    "        df = self.clean_df()\n",
    "        df = df.sample(frac=1, random_state=42)\n",
    "        df['answers'] = df[['answer_start', 'answer_text']].apply(self.convert_answers, axis=1)\n",
    "        return df\n",
    "        \n",
    "    def split_data(self):\n",
    "        df = self.shuffle()\n",
    "        df_train = df[:-64].reset_index(drop=True)\n",
    "        df_valid = df[-64:].reset_index(drop=True)\n",
    "        train_dataset = Dataset.from_pandas(df_train)\n",
    "        valid_dataset = Dataset.from_pandas(df_valid)\n",
    "        \n",
    "        return train_dataset,valid_dataset\n",
    "    \n",
    "    \n",
    "    def prepare_train_features(self,examples):\n",
    "        max_length = 384 \n",
    "        doc_stride = 128\n",
    "        pad_on_right = tokenizer.padding_side == \"right\"\n",
    "    \n",
    "        examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "        tokenized_examples = tokenizer(\n",
    "            examples[\"question\" if pad_on_right else \"context\"],\n",
    "            examples[\"context\" if pad_on_right else \"question\"],\n",
    "            truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "        offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "        tokenized_examples[\"start_positions\"] = []\n",
    "        tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "        for i, offsets in enumerate(offset_mapping):\n",
    "            input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "            cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "            sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "            sample_index = sample_mapping[i]\n",
    "            answers = examples[\"answers\"][sample_index]\n",
    "            if len(answers[\"answer_start\"]) == 0:\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                start_char = answers[\"answer_start\"][0]\n",
    "                end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "                token_start_index = 0\n",
    "                while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                    token_start_index += 1\n",
    "\n",
    "                token_end_index = len(input_ids) - 1\n",
    "                while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                    token_end_index -= 1\n",
    "\n",
    "                if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                    tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                    tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "                else:\n",
    "                    \n",
    "                    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                        token_start_index += 1\n",
    "                    tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                    while offsets[token_end_index][1] >= end_char:\n",
    "                        token_end_index -= 1\n",
    "                    tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "        return tokenized_examples\n",
    "        \n",
    "    def tokenized_df(self):\n",
    "        train_dataset,valid_dataset = self.split_data()\n",
    "        tokenized_train_ds = train_dataset.map(self.prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\n",
    "        tokenized_valid_ds = valid_dataset.map(self.prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\n",
    "        return tokenized_train_ds,tokenized_valid_ds\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T08:35:32.326275Z",
     "iopub.status.busy": "2023-01-07T08:35:32.323874Z",
     "iopub.status.idle": "2023-01-07T08:35:51.054616Z",
     "shell.execute_reply": "2023-01-07T08:35:51.053761Z",
     "shell.execute_reply.started": "2023-01-07T08:35:32.326204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab0e613fe0e43a88a409d751bb85e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc65622d068444a9d2567344e30e2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess2 = preprocess('/kaggle/input/df-tam-csv/df_tam3.csv')\n",
    "tokenizer = preprocess2.import_tokenizer('/kaggle/input/xlm-roberta-squad2/deepset/xlm-roberta-base-squad2')\n",
    "#preprocess2.token_count_distribution(tokenizer)\n",
    "train_dataset,valid_dataset = preprocess2.split_data()\n",
    "tokenized_train_ds,tokenized_valid_ds = preprocess2.tokenized_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T08:35:51.056600Z",
     "iopub.status.busy": "2023-01-07T08:35:51.056054Z",
     "iopub.status.idle": "2023-01-07T08:35:51.063683Z",
     "shell.execute_reply": "2023-01-07T08:35:51.062997Z",
     "shell.execute_reply.started": "2023-01-07T08:35:51.056560Z"
    }
   },
   "outputs": [],
   "source": [
    "class model_building:\n",
    "    \n",
    "    def __init__(self,model_checkpoint):\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "    \n",
    "    def import_model(self):\n",
    "        model = AutoModelForQuestionAnswering.from_pretrained(self.model_checkpoint)\n",
    "        return model\n",
    "    \n",
    "    def training_parameters(self,learning_rate=2e-5,batch_size = 4,weight_decay=0.01,num_train_epochs=1):\n",
    "        args = TrainingArguments(\n",
    "            f\"tamil-qa\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate=learning_rate,\n",
    "            warmup_ratio=0.1,\n",
    "            gradient_accumulation_steps=8,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "        return args\n",
    "    \n",
    "    def train_model(self, model, args, tokenized_train_ds,tokenized_valid_ds):\n",
    "        data_collator = default_data_collator\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            train_dataset=tokenized_train_ds,\n",
    "            eval_dataset=tokenized_valid_ds,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "        trainer.train()\n",
    "        \n",
    "        return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T08:35:51.065348Z",
     "iopub.status.busy": "2023-01-07T08:35:51.064802Z",
     "iopub.status.idle": "2023-01-07T09:26:03.525614Z",
     "shell.execute_reply": "2023-01-07T09:26:03.524764Z",
     "shell.execute_reply.started": "2023-01-07T08:35:51.065313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1910' max='1910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1910/1910 49:47, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.188149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>1.145816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.637100</td>\n",
       "      <td>1.294962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>1.305490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>1.434978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelbuild = model_building('/kaggle/input/xlm-roberta-squad2/deepset/xlm-roberta-base-squad2')\n",
    "model = modelbuild.import_model()\n",
    "args = modelbuild.training_parameters(num_train_epochs=5)\n",
    "trainer = modelbuild.train_model(model, args, tokenized_train_ds,tokenized_valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T09:26:03.528502Z",
     "iopub.status.busy": "2023-01-07T09:26:03.528181Z",
     "iopub.status.idle": "2023-01-07T09:26:03.546540Z",
     "shell.execute_reply": "2023-01-07T09:26:03.545530Z",
     "shell.execute_reply.started": "2023-01-07T09:26:03.528468Z"
    }
   },
   "outputs": [],
   "source": [
    "class answer_extraction:\n",
    "    \n",
    "    def __init__(self, valid_dataset):\n",
    "        self.valid_dataset = valid_dataset\n",
    "    \n",
    "    def prepare_validation_features(self,examples):\n",
    "        max_length = 384 \n",
    "        doc_stride = 128\n",
    "        pad_on_right = tokenizer.padding_side == \"right\"\n",
    "        \n",
    "        examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "        tokenized_examples = tokenizer(\n",
    "            examples[\"question\" if pad_on_right else \"context\"],\n",
    "            examples[\"context\" if pad_on_right else \"question\"],\n",
    "            truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "        tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "        for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "            sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "            context_index = 1 if pad_on_right else 0\n",
    "\n",
    "            sample_index = sample_mapping[i]\n",
    "            tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "            tokenized_examples[\"offset_mapping\"][i] = [\n",
    "                (o if sequence_ids[k] == context_index else None)\n",
    "                for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "            ]\n",
    "\n",
    "        return tokenized_examples\n",
    "    \n",
    "    def apply_validation_feature(self):\n",
    "        valid_dataset = self.valid_dataset\n",
    "        validation_features = valid_dataset.map(\n",
    "            self.prepare_validation_features,\n",
    "            batched=True,\n",
    "            remove_columns=valid_dataset.column_names\n",
    "        )\n",
    "        return validation_features\n",
    "        \n",
    "    def valid(self):\n",
    "        validation_features = self.apply_validation_feature()\n",
    "        valid_feats_small = validation_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\n",
    "        return valid_feats_small\n",
    "    \n",
    "    def raw_predict(self,trainer):\n",
    "        valid_feats_small = self.valid()\n",
    "        raw_predictions = trainer.predict(valid_feats_small)\n",
    "        return raw_predictions\n",
    "    \n",
    "    def postprocess_qa_predictions(self, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "        examples = self.valid_dataset\n",
    "        features = self.apply_validation_feature()\n",
    "        \n",
    "        all_start_logits, all_end_logits = raw_predictions\n",
    "        example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "        features_per_example = collections.defaultdict(list)\n",
    "        \n",
    "        for i, feature in enumerate(features):\n",
    "            features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "        predictions = collections.OrderedDict()\n",
    "\n",
    "        print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "        for example_index, example in enumerate(tqdm(examples)):\n",
    "            feature_indices = features_per_example[example_index]\n",
    "\n",
    "            min_null_score = None \n",
    "            valid_answers = []\n",
    "\n",
    "            context = example[\"context\"]\n",
    "            for feature_index in feature_indices: \n",
    "                start_logits = all_start_logits[feature_index]\n",
    "                end_logits = all_end_logits[feature_index]\n",
    "              \n",
    "                offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "                cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "                feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "                if min_null_score is None or min_null_score < feature_null_score:\n",
    "                    min_null_score = feature_null_score\n",
    "\n",
    "                start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                for start_index in start_indexes:\n",
    "                    for end_index in end_indexes:\n",
    "                        if (\n",
    "                            start_index >= len(offset_mapping)\n",
    "                            or end_index >= len(offset_mapping)\n",
    "                            or offset_mapping[start_index] is None\n",
    "                            or offset_mapping[end_index] is None\n",
    "                        ):\n",
    "                            continue\n",
    "                        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                            continue\n",
    "\n",
    "                        start_char = offset_mapping[start_index][0]\n",
    "                        end_char = offset_mapping[end_index][1]\n",
    "                        valid_answers.append(\n",
    "                            {\n",
    "                                \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                                \"text\": context[start_char: end_char]\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            if len(valid_answers) > 0:\n",
    "                best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "            else:\n",
    "               \n",
    "                best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T09:26:03.548414Z",
     "iopub.status.busy": "2023-01-07T09:26:03.547930Z",
     "iopub.status.idle": "2023-01-07T09:26:05.228568Z",
     "shell.execute_reply": "2023-01-07T09:26:05.227361Z",
     "shell.execute_reply.started": "2023-01-07T09:26:03.548377Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_exact_match(row):\n",
    "    return int(row[0] == row[1])\n",
    "\n",
    "def jaccard(row): \n",
    "    str1 = row[0]\n",
    "    str2 = row[1]\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def compute_f1(row):\n",
    "    truth = row[0]\n",
    "    prediction = row[1]\n",
    "    pred_tokens = prediction.split()\n",
    "    truth_tokens = truth.split()\n",
    "    \n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T09:26:05.273301Z",
     "iopub.status.busy": "2023-01-07T09:26:05.263225Z",
     "iopub.status.idle": "2023-01-07T09:26:11.059878Z",
     "shell.execute_reply": "2023-01-07T09:26:11.058680Z",
     "shell.execute_reply.started": "2023-01-07T09:26:05.273255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47d7539ee284137ac8d5e2186dc7e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112d5b26bebe42c49ec817b4bc2b355c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46ae42664b147f583d574a9bf9388e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872d03d54ab34524a4beb62cee69643c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ccbbdcc35c4423b49d5681668fbb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing2 = answer_extraction(valid_dataset)\n",
    "validation_features = testing2.apply_validation_feature()\n",
    "valid_feats_small = testing2.valid()\n",
    "raw_predictions = testing2.raw_predict(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T09:26:11.068229Z",
     "iopub.status.busy": "2023-01-07T09:26:11.065545Z",
     "iopub.status.idle": "2023-01-07T09:26:12.584308Z",
     "shell.execute_reply": "2023-01-07T09:26:12.583552Z",
     "shell.execute_reply.started": "2023-01-07T09:26:11.068175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39c3f84a59144b28a3a7d13f37d4a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 64 example predictions split into 169 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64e3205c67149c8bfda3e7f426b1733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = testing2.postprocess_qa_predictions( \n",
    "                                    raw_predictions.predictions, n_best_size = 20, \n",
    "                                    max_answer_length = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T09:26:12.589760Z",
     "iopub.status.busy": "2023-01-07T09:26:12.587849Z",
     "iopub.status.idle": "2023-01-07T09:26:12.911083Z",
     "shell.execute_reply": "2023-01-07T09:26:12.906659Z",
     "shell.execute_reply.started": "2023-01-07T09:26:12.589719Z"
    }
   },
   "outputs": [],
   "source": [
    "references = [{\"id\": ex[\"id\"], \"answer_text\": ex[\"answers\"]['text'][0]} for ex in valid_dataset]\n",
    "res = pd.DataFrame(references)\n",
    "res['prediction'] = res['id'].apply(lambda r: predictions[r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T09:31:20.866629Z",
     "iopub.status.busy": "2023-01-07T09:31:20.866307Z",
     "iopub.status.idle": "2023-01-07T09:31:20.889033Z",
     "shell.execute_reply": "2023-01-07T09:31:20.888092Z",
     "shell.execute_reply.started": "2023-01-07T09:31:20.866596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>e693ffa1</td>\n",
       "      <td>720 களுக்குப் பிறகு</td>\n",
       "      <td>கிமு 720</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>83f94fe8</td>\n",
       "      <td>உயிரியல்</td>\n",
       "      <td>தாமிரம் உயிரியல்</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>08fc5f48</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>28f9e6ea</td>\n",
       "      <td>கோல்கொண்டா</td>\n",
       "      <td>கோல்கொண்டா</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1fc78dff</td>\n",
       "      <td>ஹிரூ</td>\n",
       "      <td>ஹிரூ</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          answer_text        prediction  jaccard  EM        F1\n",
       "59  e693ffa1  720 களுக்குப் பிறகு          கிமு 720     0.25   0  0.400000\n",
       "60  83f94fe8             உயிரியல்  தாமிரம் உயிரியல்     0.50   0  0.666667\n",
       "61  08fc5f48                   11                11     1.00   0  1.000000\n",
       "62  28f9e6ea           கோல்கொண்டா        கோல்கொண்டா     1.00   0  1.000000\n",
       "63  1fc78dff                 ஹிரூ              ஹிரூ     1.00   0  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['jaccard'] = res[['answer_text', 'prediction']].apply(jaccard, axis=1)\n",
    "res ['EM'] = res[['answer_text', 'prediction']].apply(compute_exact_match, axis=1)\n",
    "res ['F1'] = res[['answer_text', 'prediction']].apply(compute_f1, axis=1)\n",
    "res.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-07T09:31:21.657643Z",
     "iopub.status.busy": "2023-01-07T09:31:21.657319Z",
     "iopub.status.idle": "2023-01-07T09:31:21.665556Z",
     "shell.execute_reply": "2023-01-07T09:31:21.664549Z",
     "shell.execute_reply.started": "2023-01-07T09:31:21.657610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.5772845643939393\n",
      "Jaccard score:  0.5378348214285714\n",
      "Exact match score:  0.125\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score: ',res.F1.mean())\n",
    "print('Jaccard score: ',res.jaccard.mean())\n",
    "print('Exact match score: ', res.EM.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
